{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visual transformers(K).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP39MsR-kje0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mk6ieqTlNDN"
      },
      "source": [
        "# deciding the transformes to apply to the dataset\n",
        "transform = transforms.Compose( [transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_st8xPfl4aw",
        "outputId": "77b8b88a-cd35-4688-ba4e-da2edb7dc327"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        " \n",
        "# Downloading the training set of CIFAR10 dataset, and getting a trainloader\n",
        "trainset    = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                           train=True,\n",
        "                                           download=True, \n",
        "                                           transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True, \n",
        "                                          num_workers=2)\n",
        " \n",
        "# Downloading the test set of CIFAR10 dataset, and getting a testloader\n",
        "testset    = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                          train=False,\n",
        "                                          download=True, \n",
        "                                          transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False, \n",
        "                                         num_workers=2)\n",
        "\n",
        "# specifying the classes\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', \n",
        "           'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWSPlEoymBqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947adcd3-59c5-4062-8dd0-a44d8f5774e8"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# image.shape = [batch, channels, height, width]\n",
        "print(images.shape)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW5ZVZXNqp28"
      },
      "source": [
        "# As specified in the paper, \n",
        "# l = number of tokens\n",
        "# c = channels, \n",
        "l, c = 16, 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WyNYnPeADBh"
      },
      "source": [
        "class Tokenizer(nn.Module):\n",
        "\n",
        "  def __init__(self, device, L):\n",
        "    super().__init__()\n",
        " \n",
        "    self.L = L\n",
        "\n",
        "    # Getting image features through layers of convolution\n",
        "    # convolutional Layer 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
        "    self.mxp1  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # convolutional Layer 2\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=1)\n",
        "    self.mxp2  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # convolutional Layer 3\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.mxp3  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # convolutional Layer 4\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1)\n",
        "    self.mxp4  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    # convolutional Layer 5\n",
        "    self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "    self.mxp5  = nn.MaxPool2d(kernel_size=2,  stride=2)\n",
        "    \n",
        "    # The fully connected layers to get tokens\n",
        "    self.fc1   = nn.Linear(512, L, bias=False)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "      # x = [batch, channels, heigth, width]\n",
        "      x = self.conv1(x)\n",
        "      x = self.mxp1(x)\n",
        "      x = F.relu(x)\n",
        " \n",
        "      x = self.conv2(x)\n",
        "      # x = self.mxp2(x)\n",
        "      x = F.relu(x)\n",
        " \n",
        "      x = self.conv3(x)\n",
        "      x = self.mxp3(x)\n",
        "      x = F.relu(x) \n",
        "\n",
        "      x = self.conv4(x)\n",
        "      # x = self.mxp4(x)\n",
        "      x = F.relu(x) \n",
        "\n",
        "      x = self.conv5(x)\n",
        "      x = self.mxp5(x)\n",
        "      x = F.relu(x)                          # x = [batch, C, heigth, width]\n",
        " \n",
        "      x = x.view(x.shape[0], x.shape[1], -1) # x = [batch, C, heigth*width]\n",
        "      \n",
        "      x1 = x.permute(0,2,1)                  # x1 = [batch, H*W, C]\n",
        "      x2 = x.permute(0,2,1)                  # x2 = [batch, H*W, C]\n",
        " \n",
        "      x1 = self.fc1(x1)                      # x1 = [batch, H*W, L]\n",
        "      x1 = x1.permute(0,2,1)                 # x1 = [batch, L, H*W]\n",
        " \n",
        "      x1 = F.softmax(x1, dim=-1)\n",
        "      t = torch.matmul(x1,x2)                # t = [batch, L, C]\n",
        "\n",
        "      return t, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rw5G0rQFGCh"
      },
      "source": [
        "# As specified in the paper, \n",
        "# l = number of tokens,\n",
        "# c = channels\n",
        "class Recurrent_tokenizer(nn.Module):\n",
        "\n",
        "  def __init__(self, device, l, c):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    # get weights from previous token\n",
        "    self.token2wt = nn.Linear(c, c, bias=False)\n",
        "    \n",
        "  def forward(self, x, token):\n",
        "    \n",
        "    # token = [batch, L, C]\n",
        "    # X = [batch, C, H*W]\n",
        "\n",
        "    Wr = self.token2wt(token) #Wr = [batch, L, C]\n",
        "    Wr = Wr.permute(0,2,1)    #Wr = [batch, C, L]\n",
        "    \n",
        "    x = x.permute(0,2,1)      #x = [batch, H*W, C]\n",
        "\n",
        "    a = torch.matmul(x,Wr)    #a = [batch, H*W, C] x [batch, C, L] = [batch, H*W, L]\n",
        "    a = a.permute(0,2,1)      #a = [batch, L, H*W]\n",
        "    a = F.softmax(a, dim=-1)\n",
        "\n",
        "    t = torch.matmul(a,x)     #t = [batch, L, H*W] x  [batch, H*W, C] = [batch, L, C]\n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnrJ-KemFGAg"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self, l, c):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    self.token2Q = nn.Linear(c,c,bias=False)\n",
        "    self.token2K = nn.Linear(c,c,bias=False)\n",
        "\n",
        "    self.F1 = nn.Conv1d(in_channels=c,out_channels=c,kernel_size=1)\n",
        "    self.F2 = nn.Conv1d(in_channels=c,out_channels=c,kernel_size=1)\n",
        " \n",
        "  def forward(self, token):\n",
        "\n",
        "    # getting the key and query weights\n",
        "    Tk = self.token2K(token)\n",
        "    Tq = self.token2Q(token)\n",
        "    Tq = Tq.permute(0,2,1)\n",
        "\n",
        "    a = torch.matmul(Tk,Tq)\n",
        "    a = F.softmax(a,dim=-1)\n",
        "    a = torch.matmul(a,token)\n",
        "\n",
        "    T = token + a          #T = [batch, l, c]\n",
        "    T = T.permute(0,2,1)\n",
        "\n",
        "    T1 = self.F1(T)\n",
        "    T1 = F.relu(T1)\n",
        "    T1 = self.F2(T1)\n",
        "    T1 = T1 + T            #T1 = [batch, l, c]\n",
        "    T1 = T1.permute(0,2,1) #T1 = [batch, c, l]\n",
        "\n",
        "    return T1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNJvXMbQFF9q"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "\n",
        "  def __init__(self, l, c):\n",
        "\n",
        "    super().__init__()\n",
        "    self.c = c\n",
        "    self.l = l\n",
        "    \n",
        "    self.avgPool = nn.AvgPool1d(kernel_size=3,stride=1)\n",
        "    self.fc1     = nn.Linear((l-2)*c,512)\n",
        "    self.fc2     = nn.Linear(512,10)\n",
        " \n",
        "  def forward(self,x):  \n",
        "    \n",
        "    # x = [batch, l, c]\n",
        "\n",
        "    x = x.permute(0,2,1)             # x = [batch, c, l]    \n",
        "    x = self.avgPool(x)\n",
        "\n",
        "    x = x.permute(0,2,1)\n",
        "    x = x.reshape(x.shape[0],-1)     # x = [batch, c*l]\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "   \n",
        "    return x                         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk31xXrTLFei"
      },
      "source": [
        "# Get the 1st token\n",
        "tokenizer = Tokenizer(device='cuda', L=16)\n",
        "\n",
        "# pass the consecutive tokens to recurrent tokenizer\n",
        "recurrent_tokenizer1 = Recurrent_tokenizer(device='cuda', l=16, c=512)\n",
        "recurrent_tokenizer2 = Recurrent_tokenizer(device='cuda', l=16, c=512)\n",
        "recurrent_tokenizer3 = Recurrent_tokenizer(device='cuda', l=16, c=512)\n",
        "recurrent_tokenizer4 = Recurrent_tokenizer(device='cuda', l=16, c=512)\n",
        "\n",
        "# Transformer for the final token\n",
        "transformer = Transformer(l=16, c=512)\n",
        "\n",
        "# Final classification\n",
        "classifier = Classifier(l=16, c=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkjRodTjFF6x"
      },
      "source": [
        "class DaMixer(nn.Module):\n",
        "\n",
        "  def __init__(self,tokenizer, recurrent_tokenizer1, \n",
        "               recurrent_tokenizer2, recurrent_tokenizer3, \n",
        "               recurrent_tokenizer4, transformer, classifier):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "    self.recurrent_tokenizer1 = recurrent_tokenizer1\n",
        "    self.recurrent_tokenizer2 = recurrent_tokenizer2\n",
        "    self.recurrent_tokenizer3 = recurrent_tokenizer3\n",
        "    self.recurrent_tokenizer4 = recurrent_tokenizer4\n",
        "\n",
        "    self.transformer = transformer\n",
        "    \n",
        "    self.classifier = classifier\n",
        " \n",
        "  def forward(self, x):\n",
        "\n",
        "    t, features = self.tokenizer(x)\n",
        "\n",
        "    t = self.recurrent_tokenizer1(features,t)\n",
        "    t = self.recurrent_tokenizer2(features,t)\n",
        "    t = self.recurrent_tokenizer3(features,t)\n",
        "    t = self.recurrent_tokenizer4(features,t)\n",
        "\n",
        "    t = self.transformer(t)\n",
        "    op = self.classifier(t)\n",
        "\n",
        "    return op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfh8qAVmFF4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1f0d31-23ce-45b3-c5ec-59f985640d56"
      },
      "source": [
        "model = DaMixer(tokenizer,recurrent_tokenizer1, recurrent_tokenizer2, \n",
        "                recurrent_tokenizer3, recurrent_tokenizer4, transformer, \n",
        "                classifier).to('cuda')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DaMixer(\n",
            "  (tokenizer): Tokenizer(\n",
            "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (mxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (mxp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (mxp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (mxp4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (mxp5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (fc1): Linear(in_features=512, out_features=16, bias=False)\n",
            "  )\n",
            "  (recurrent_tokenizer1): Recurrent_tokenizer(\n",
            "    (token2wt): Linear(in_features=512, out_features=512, bias=False)\n",
            "  )\n",
            "  (recurrent_tokenizer2): Recurrent_tokenizer(\n",
            "    (token2wt): Linear(in_features=512, out_features=512, bias=False)\n",
            "  )\n",
            "  (recurrent_tokenizer3): Recurrent_tokenizer(\n",
            "    (token2wt): Linear(in_features=512, out_features=512, bias=False)\n",
            "  )\n",
            "  (recurrent_tokenizer4): Recurrent_tokenizer(\n",
            "    (token2wt): Linear(in_features=512, out_features=512, bias=False)\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (token2Q): Linear(in_features=512, out_features=512, bias=False)\n",
            "    (token2K): Linear(in_features=512, out_features=512, bias=False)\n",
            "    (F1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "    (F2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (classifier): Classifier(\n",
            "    (avgPool): AvgPool1d(kernel_size=(3,), stride=(1,), padding=(0,))\n",
            "    (fc1): Linear(in_features=7168, out_features=512, bias=True)\n",
            "    (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPVb2V29Kj1D",
        "outputId": "fa8f810c-81f4-4900-bccb-0a3ea5740bcb"
      },
      "source": [
        "# Get number of parameters in tabular form\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "      \n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    \n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------+------------+\n",
            "|               Modules                | Parameters |\n",
            "+--------------------------------------+------------+\n",
            "|        tokenizer.conv1.weight        |    432     |\n",
            "|         tokenizer.conv1.bias         |     16     |\n",
            "|        tokenizer.conv2.weight        |    1024    |\n",
            "|         tokenizer.conv2.bias         |     64     |\n",
            "|        tokenizer.conv3.weight        |   73728    |\n",
            "|         tokenizer.conv3.bias         |    128     |\n",
            "|        tokenizer.conv4.weight        |   32768    |\n",
            "|         tokenizer.conv4.bias         |    256     |\n",
            "|        tokenizer.conv5.weight        |  1179648   |\n",
            "|         tokenizer.conv5.bias         |    512     |\n",
            "|         tokenizer.fc1.weight         |    8192    |\n",
            "| recurrent_tokenizer1.token2wt.weight |   262144   |\n",
            "| recurrent_tokenizer2.token2wt.weight |   262144   |\n",
            "| recurrent_tokenizer3.token2wt.weight |   262144   |\n",
            "| recurrent_tokenizer4.token2wt.weight |   262144   |\n",
            "|      transformer.token2Q.weight      |   262144   |\n",
            "|      transformer.token2K.weight      |   262144   |\n",
            "|        transformer.F1.weight         |   262144   |\n",
            "|         transformer.F1.bias          |    512     |\n",
            "|        transformer.F2.weight         |   262144   |\n",
            "|         transformer.F2.bias          |    512     |\n",
            "|        classifier.fc1.weight         |  3670016   |\n",
            "|         classifier.fc1.bias          |    512     |\n",
            "|        classifier.fc2.weight         |    5120    |\n",
            "|         classifier.fc2.bias          |     10     |\n",
            "+--------------------------------------+------------+\n",
            "Total Trainable Params: 7070602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7070602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIWh9RVGFF1v"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the network for classification\n",
        "def train(train_iterator, optimizer, criterion, model, EPOCHS):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = []\n",
        "  x_list = []\n",
        "\n",
        "  for i in range(EPOCHS):\n",
        "\n",
        "    acc=0\n",
        "    for n,data in enumerate(train_iterator):\n",
        "\n",
        "      images, labels = data                # images = [batch, c, height, width]\n",
        "                                           # labels = [batch]\n",
        "      images = images.to('cuda')\n",
        "      labels = labels.to('cuda')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(images)               # output = [batch, classes]\n",
        "\n",
        "      loss = criterion(output,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      acc+=loss.item()\n",
        "      \n",
        "    epoch_loss.append(acc/(n+1))\n",
        "    x_list.append(i+1)\n",
        "\n",
        "    if i%10==0:\n",
        "      print(\"Epoch : {} | Loss : {}\".format(i, epoch_loss[-1]))\n",
        "\n",
        "  plt.plot(x_list, epoch_loss)\n",
        "  plt.show()\n",
        "\n",
        "  return epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rGUsnhZFFy2"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWxGxVfEFFwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1259d3c-7da9-48ba-ed11-5fb69f34d877"
      },
      "source": [
        "loss = train(trainloader, optimizer, criterion, model, 200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 | Loss : 1.6937650166790377\n",
            "Epoch : 10 | Loss : 0.4257059591516652\n",
            "Epoch : 20 | Loss : 0.07439357585301093\n",
            "Epoch : 30 | Loss : 0.04514172839273649\n",
            "Epoch : 40 | Loss : 0.02666192329607645\n",
            "Epoch : 50 | Loss : 0.025301044028955305\n",
            "Epoch : 60 | Loss : 0.023128898299315553\n",
            "Epoch : 70 | Loss : 0.017903911687267734\n",
            "Epoch : 80 | Loss : 0.01541719901894232\n",
            "Epoch : 90 | Loss : 0.013450883309585843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc9759b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : 100 | Loss : 0.013086103334825117\n",
            "Epoch : 110 | Loss : 0.012371785295847582\n",
            "Epoch : 120 | Loss : 0.009608134788765469\n",
            "Epoch : 130 | Loss : 0.010478851536691813\n",
            "Epoch : 140 | Loss : 0.009485929846671794\n",
            "Epoch : 150 | Loss : 0.00916315113315443\n",
            "Epoch : 160 | Loss : 0.01060256454297172\n",
            "Epoch : 170 | Loss : 0.006988117932003493\n",
            "Epoch : 180 | Loss : 0.009289736553557398\n",
            "Epoch : 190 | Loss : 0.00776273763094086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UVmdDKpG1Sw",
        "outputId": "6a04801c-c2ce-47d8-837b-34a8c100eb20"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        # print(images.shape)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        " \n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 74 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}